# ğŸš€ Scraping Websites with Selenium, BeautifulSoup & Playwright

This repository provides a scalable framework for scraping property listings across multiple sites using **Selenium** ğŸ§ª, **BeautifulSoup** ğŸ¥£, and **Playwright** ğŸ­. It supports parallel execution of two main scripts in each target folder:

1. **`url_extractor.py`** ğŸ“¥ â€“ Collects and stores property URLs.
2. **`detail_extractor.py`** ğŸ“‹ â€“ Navigates to each URL and extracts detailed information.

A Dockerfile ğŸ³ is included for containerized execution, ensuring consistent environments and easy deployment.

## âœ¨ Features

* Folder-based organization for multiple websites ğŸ“‚
* Dockerized workflow with a single base image (Python 3.11 slim) ğŸ³
* Chromium browser packaged inside the container ğŸŒ
* AWS SNS integration for post-run notifications ğŸ””
* Slack notifications for start, completion, and inactivity alerts ğŸ’¬

## ğŸ”§ Prerequisites

* Docker installed on your system ğŸ³
* AWS CLI configured with credentials that have access to ECR (if using ECR images) ğŸ”‘
* A valid Slack webhook URL stored in `slack_webhook_url` within the main script ğŸ”—
* Optional: AWS SNS topic ARN for final termination messages ğŸ›°ï¸

## âš™ï¸ Setup & Build

1. **Clone the repo** ğŸ“¥

   ```bash
   git clone <your-repo-url> && cd <repo-dir>
   ```

2. **Build the Docker image** ğŸ› ï¸

   ```bash
   docker build -t scraping-scripts:latest .
   ```

## â–¶ï¸ Usage

### Local Execution ğŸ–¥ï¸

Run the main orchestrator script directly (requires Python dependencies installed):

```bash
python3 main.py --folders ethiopian_properties global_remax ...
```

### Docker Execution ğŸ³ğŸš€

Use the container image for a clean, repeatable run:

```bash
docker run --rm \
  -v "$PWD":/usr/src/app \
  scraping-scripts:latest \
  main.py --folders ethiopian_properties global_remax ...
```

The `ENTRYPOINT ["python3"]` in the Dockerfile ensures that any passed arguments are executed as a Python command.

## ğŸ³ Dockerfile Breakdown

```Dockerfile
# Base image: lightweight Python
FROM python:3.11-slim
WORKDIR /usr/src/app
COPY . .

# Install Chromium for headless browsing
RUN apt update && apt install -y chromium chromium-driver

# Upgrade pip and install Python deps
RUN pip install --upgrade pip setuptools wheel
RUN pip install --no-cache-dir --ignore-installed -r requirements.txt

# ENTRYPOINT to run Python scripts directly
ENTRYPOINT ["python3"]
```

## ğŸ” Script Details

* **`docker.py`** orchestrates container launches per folder and script.
* **`monitor_container`** (optional) tracks container logs and sends Slack alerts on inactivity.
* **AWS SNS** message at the end signals downstream processes (e.g., EC2 termination).

## ğŸŒ Environment Variables

* `slack_webhook_url` ğŸ”—: Your Slack incoming webhook endpoint.
* `AWS_PROFILE`, `AWS_REGION`, `AWS_ACCOUNT_ID`, `ECR_REPO_NAME` ğŸ› ï¸: If pulling/pushing images from ECR.
* `SNS_TOPIC_ARN` ğŸ›°ï¸: Topic to publish termination instructions.

## ğŸš€ Extending

1. Add new folders under the root directory matching target sites.
2. Place or adapt `url_extractor.py` and `detail_extractor.py` in each folder.
3. Adjust threading, timeouts, or notification logic in `docker.py` as needed.

---

ğŸ‰ Happy scraping! ğŸ•¸ï¸
