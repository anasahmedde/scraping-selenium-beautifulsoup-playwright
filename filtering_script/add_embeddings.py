from langchain.embeddings import OpenAIEmbeddings
import os
import pandas as pd
from tenacity import retry, stop_after_attempt, wait_fixed

# Initialize the OpenAI embeddings client
openai_key = os.getenv("openai_key")
client_embedding = OpenAIEmbeddings(api_key=openai_key)

def generate_embedded_description(row: pd.Series) -> str:
    """
    Build the text prompt that will be embedded for each listing.
    """
    description = "Listing summary:\n\n"

    if not pd.isnull(row.get('housingType')):
        description += f"Listing type: {row['housingType']}\n"
    
    if not pd.isnull(row.get('type')):
        description += f"Listing status: for {row['type']}\n"
    
    # Location logic
    if all(pd.notnull(row.get(f)) for f in ['consolidatedNeighbourhood','consolidatedCity','consolidatedState','consolidatedCountry']):
        description += f"Location: {row['consolidatedNeighbourhood']}, {row['consolidatedCity']}, {row['consolidatedState']}, {row['consolidatedCountry']}\n"
    elif all(pd.notnull(row.get(f)) for f in ['consolidatedNeighbourhood','consolidatedCity','consolidatedCountry']):
        description += f"Location: {row['consolidatedNeighbourhood']}, {row['consolidatedCity']}, {row['consolidatedCountry']}\n"
    elif pd.notnull(row.get('consolidatedCity')) and pd.notnull(row.get('consolidatedCountry')):
        description += f"Location: {row['consolidatedCity']}, {row['consolidatedCountry']}\n"
    elif pd.notnull(row.get('locationAddress')):
        description += f"Location: {row['locationAddress']}\n"

    # Beds & baths
    if not pd.isnull(row.get('beds')) and not pd.isnull(row.get('baths')):
        try:
            description += f"Beds & baths: {int(row['beds'])} Beds, {int(row['baths'])} Baths\n"
        except ValueError:
            description += f"Beds & baths: {row['beds']} Beds, {row['baths']} Baths\n"

    # Area
    if 'internalArea' in row and not pd.isnull(row['internalArea']):
        description += f"Size: {row['internalArea']} square feet\n"

    # Price
    if not pd.isnull(row.get('price')):
        description += f"Price: {int(row['price'])} USD\n"
    if not pd.isnull(row.get('pricePerSf')):
        description += f"Price per square ft: {row['pricePerSf']}\n"
    if not pd.isnull(row.get('cumulativePriceChange')):
        description += f"Cumulative Price change: {row['cumulativePriceChange']}\n"
    if not pd.isnull(row.get('priceStatus')) and not pd.isnull(row.get('priceDiff')):
        description += f"Latest Price change: {row['priceStatus']} by {row['priceDiff']}\n"

    # Time on market
    if not pd.isnull(row.get('daysOnMarket')):
        description += f"Days on market: {row['daysOnMarket']} days\n"

    # Amenities
    amenities = row.get('amenities')
    if isinstance(amenities, (list, tuple)) and amenities:
        description += f"Amenities: {', '.join(amenities)}."

    # Free text description
    if not pd.isnull(row.get('description')):
        description += f"\n\nListing description:\n\n{row['description']}"

    return description.strip()

# Optional: retry decorator if you want to retry the entire batch on failure
# @retry(stop=stop_after_attempt(3), wait=wait_fixed(10))
def add_embeddings(df: pd.DataFrame, batch_size: int = 100) -> pd.DataFrame:
    """
    Adds two new columns to the DataFrame:
      - 'description_embedding': the raw prompt text
      - 'embedding': the embedding vector generated by OpenAI in batched requests

    Args:
      df: DataFrame containing listing records.
      batch_size: How many descriptions to send per API call.

    Returns:
      The same DataFrame with an added 'embedding' column.
    """
    # 1) Build the text for each row
    df['description_embedding'] = df.apply(generate_embedded_description, axis=1)
    descriptions = df['description_embedding'].tolist()

    # 2) Batch the embedding calls
    all_embeddings = []
    for i in range(0, len(descriptions), batch_size):
        batch = descriptions[i : i + batch_size]
        # This sends one HTTP request per batch
        batch_embeds = client_embedding.embed_documents(batch)
        all_embeddings.extend(batch_embeds)

    # 3) Attach embeddings back to the DataFrame
    df['embedding'] = all_embeddings
    return df
